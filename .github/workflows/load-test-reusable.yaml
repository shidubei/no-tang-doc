name: Load Test (Reusable)

on:
  workflow_call:
    inputs:
      service:
        description: 'Service to test (agent/core/web)'
        required: true
        type: string
      script:
        description: 'Test script filename (e.g., agent-api.js)'
        required: true
        type: string
      environment:
        description: 'Target environment (development/production)'
        required: false
        type: string
        default: 'production'
      scenario:
        description: 'Test scenario (smoke/load/stress/spike/soak/ci)'
        required: false
        type: string
        default: 'load'
      test_team_id:
        description: 'Test team ID for API calls'
        required: false
        type: string
        default: '1'
    secrets:
      KEYCLOAK_CLIENT_ID:
        required: true
      KEYCLOAK_CLIENT_SECRET:
        required: true

env:
  K6_VERSION: '0.54.0'

jobs:
  load-test:
    name: k6 Load Test - ${{ inputs.service }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup k6
        uses: grafana/setup-k6-action@v1
        with:
          k6-version: ${{ env.K6_VERSION }}

      - name: Validate test script exists
        run: |
          if [ ! -f "load-tests/k6/scripts/${{ inputs.script }}" ]; then
            echo "‚ùå Test script not found: load-tests/k6/scripts/${{ inputs.script }}"
            exit 1
          fi
          echo "‚úÖ Test script found: load-tests/k6/scripts/${{ inputs.script }}"

      - name: Run k6 load test
        id: k6-test
        env:
          ENVIRONMENT: ${{ inputs.environment }}
          SCENARIO: ${{ inputs.scenario }}
          KEYCLOAK_CLIENT_ID: ${{ secrets.KEYCLOAK_CLIENT_ID }}
          KEYCLOAK_CLIENT_SECRET: ${{ secrets.KEYCLOAK_CLIENT_SECRET }}
          TEST_TEAM_ID: ${{ inputs.test_team_id }}
        run: |
          echo "üöÄ Starting k6 load test for ${{ inputs.service }}"
          echo "   Script: ${{ inputs.script }}"
          echo "   Environment: ${{ inputs.environment }}"
          echo "   Scenario: ${{ inputs.scenario }}"
          echo ""
          
          k6 run \
            --out json=load-tests/results/results-${{ inputs.service }}-${{ github.run_id }}.json \
            --summary-export=load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json \
            load-tests/k6/scripts/${{ inputs.script }} \
            || echo "test_failed=true" >> $GITHUB_OUTPUT

      - name: Check test results
        id: check-results
        if: always()
        run: |
          if [ -f "load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json" ]; then
            echo "‚úÖ Test completed - Checking thresholds..."
            
            # Parse summary to check if all thresholds passed
            FAILED_THRESHOLDS=$(jq -r '.metrics | to_entries[] | select(.value.thresholds != null) | select(.value.thresholds | to_entries[] | select(.value.ok == false)) | .key' load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json | wc -l)
            
            if [ "$FAILED_THRESHOLDS" -gt 0 ]; then
              echo "‚ùå $FAILED_THRESHOLDS threshold(s) failed"
              echo "threshold_status=failed" >> $GITHUB_OUTPUT
            else
              echo "‚úÖ All thresholds passed"
              echo "threshold_status=passed" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ùå No test summary found"
            echo "threshold_status=error" >> $GITHUB_OUTPUT
          fi

      - name: Generate summary report
        if: always()
        run: |
          echo "## üìä Load Test Results - ${{ inputs.service }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Service:** ${{ inputs.service }}" >> $GITHUB_STEP_SUMMARY
          echo "**Script:** ${{ inputs.script }}" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Scenario:** ${{ inputs.scenario }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run ID:** ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json" ]; then
            echo "### Key Metrics" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            jq -r '
              "HTTP Requests:",
              "  Total: \(.metrics.http_reqs.values.count // 0)",
              "  Rate: \(.metrics.http_reqs.values.rate // 0 | tonumber | . * 100 | round / 100) req/s",
              "  Failed: \(.metrics.http_req_failed.values.rate // 0 | tonumber | . * 100 | round)%",
              "",
              "Response Times:",
              "  Avg: \(.metrics.http_req_duration.values.avg // 0 | tonumber | round)ms",
              "  p95: \(.metrics.http_req_duration.values["p(95)"] // 0 | tonumber | round)ms",
              "  p99: \(.metrics.http_req_duration.values["p(99)"] // 0 | tonumber | round)ms",
              "  Max: \(.metrics.http_req_duration.values.max // 0 | tonumber | round)ms",
              "",
              "Virtual Users:",
              "  Max: \(.metrics.vus_max.values.max // 0)",
              "",
              "Checks:",
              "  Success Rate: \(.metrics.checks.values.rate // 0 | tonumber | . * 100 | round)%"
            ' load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Threshold status
            if [ "${{ steps.check-results.outputs.threshold_status }}" = "passed" ]; then
              echo "### ‚úÖ Thresholds: PASSED" >> $GITHUB_STEP_SUMMARY
            elif [ "${{ steps.check-results.outputs.threshold_status }}" = "failed" ]; then
              echo "### ‚ùå Thresholds: FAILED" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Failed thresholds:" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              jq -r '.metrics | to_entries[] | select(.value.thresholds != null) | select(.value.thresholds | to_entries[] | select(.value.ok == false)) | "\(.key): \(.value.thresholds | to_entries[] | select(.value.ok == false) | .key)"' load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ö†Ô∏è No test results available" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-results-${{ inputs.service }}-${{ github.run_id }}
          path: |
            load-tests/results/results-${{ inputs.service }}-${{ github.run_id }}.json
            load-tests/results/summary-${{ inputs.service }}-${{ github.run_id }}.json
          retention-days: 30

      - name: Fail workflow if thresholds not met
        if: steps.check-results.outputs.threshold_status == 'failed'
        run: |
          echo "‚ùå Load test failed - Performance thresholds not met"
          exit 1
